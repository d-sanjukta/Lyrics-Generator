{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "xoDBrdpIm9hU",
        "arqm_EEtvGeo",
        "kptJpR15Ju1q",
        "a2XnZk0QS7Ur",
        "WfWf0DxmhgqP",
        "5QTUqd618WTG",
        "RmmAp1LGJjoZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d-sanjukta/Lyrics-Generator/blob/main/3_Artist_specific_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b>3. <u>FINE TUNING TRAINED LLM (ARTIST SPECIFIC TRAINNIG)</b></u>\n",
        "\n",
        "* We will fine-tune the genre-based language models on five selected artists for each specific genre.\n",
        "* This process aims to capture the unique style and characteristics of each artist, enabling the generation of content that reflects their artistic expression and creativity.\n",
        "\n",
        "\n",
        "______________________________________________________________________________________________________________"
      ],
      "metadata": {
        "id": "xoDBrdpIm9hU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers\n",
        "# !pip install datasets\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel,pipeline\n",
        "import re"
      ],
      "metadata": {
        "id": "ZIaSEfcluChE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttTfjWn1uT6q",
        "outputId": "9cdcc204-5d35-4850-faf3-86a7b02888d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FUNCTIONS\n"
      ],
      "metadata": {
        "id": "arqm_EEtvGeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## FUNCTION TO PRE_PROCESS THE DATA :\n",
        "\n",
        "def pre_processing_lyrics(dataset):\n",
        "  '''\n",
        "  INPUT : Dataset having different features like : genre , artist , title , view , lyrics etc\n",
        "  Here, we are interested only in lyrics.\n",
        "  Output: Processed list of Songs/ lyrics\n",
        "  '''\n",
        "  # extracting lyrics from dataset\n",
        "  try :\n",
        "    songs  = list(dataset['lyrics'])\n",
        "  except:\n",
        "    songs  = list(dataset['Lyric'])\n",
        "\n",
        "\n",
        "  # REMOVE ANY WORDS CONTAINING NUMERICAL VALUE and SPECIAL CHARACTERS.\n",
        "  final_lyrics = []\n",
        "  pattern = re.compile(r'\\b[^\\W\\d_]+\\b')  # Regex pattern to match words without numerical characters\n",
        "\n",
        "  for lyric in songs:\n",
        "        splits = str(lyric).split(',')\n",
        "        cleaned_splits = []\n",
        "\n",
        "        for split in splits:\n",
        "            cleaned_split = re.sub(r'[^\\w\\s\\']', '', split)\n",
        "            filtered_split = ' '.join(word for word in cleaned_split.split() if pattern.match(word))\n",
        "            cleaned_splits.append(filtered_split)\n",
        "\n",
        "        final_lyrics.append(','.join(cleaned_splits))\n",
        "\n",
        "\n",
        "  # Applygin 'next line' token at every capital Letter in lyrics and 'end of sequence' token.\n",
        "  final_lyrics  = [' '.join(['\\n' + word if (word[0]).isupper() else word for word in songs.replace('  ', '').split(' ')] + [' </s>']) for songs in final_lyrics]\n",
        "  print (f\"Number of Total Processed Lyrics : {len(final_lyrics)}\")\n",
        "\n",
        "  return final_lyrics\n",
        "\n",
        "##############################################################################################################################################################################\n",
        "\n",
        "# Function to make chunks of equal number of words: default = 128 words/tokens\n",
        "\n",
        "def create_chunks(tokens , window = 128, stride = 20):\n",
        "  chunks = [] # list to contains chunks of 128 words.\n",
        "  start = 0\n",
        "  end = window\n",
        "\n",
        "  while end < len(tokens):\n",
        "    chunks.append(tokens[start:end])\n",
        "    start +=stride\n",
        "    end +=stride\n",
        "\n",
        "  return chunks\n",
        "\n",
        "# Define the  function to take inputs and generate labels and masks.\n",
        "def create_data(inputs):\n",
        "    input_ids = inputs[:-1]\n",
        "    target_ids = inputs[1:]\n",
        "\n",
        "    return {'input_ids': input_ids, 'attention_mask': tf.ones_like(input_ids)}, target_ids\n",
        "\n",
        "##################################################################################################################################################################\n",
        "\n",
        "## FUNCTION TO PREPARE THE 'TENSORFLOW' DATASET:\n",
        "\n",
        "def prepare_dataset(lyrics, model = 'gpt2',n_words = 128  ):\n",
        "  '''\n",
        "  Input : takes in the list of lyrics & the pre-trained tokenizer.\n",
        "  Output: return the tensorflow datasets.\n",
        "  '''\n",
        "\n",
        "  # Split the lyrics into train and validation sets\n",
        "  val_split = 0.2  # 20% of the data will be used for validation\n",
        "\n",
        "  split_index = int(len(lyrics) * (1 - val_split))\n",
        "  train_lyrics = lyrics[:split_index]\n",
        "  val_lyrics = lyrics[split_index:]\n",
        "\n",
        "  # Load the pre-trained GPT-2 tokenizer\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained(model)\n",
        "\n",
        "  # Tokenize the train and validation lyrics\n",
        "  encoded_train_lyrics = np.concatenate([tokenizer.encode(l) for l in train_lyrics if tokenizer.encode(l)])\n",
        "  encoded_val_lyrics = np.concatenate([tokenizer.encode(l) for l in val_lyrics if tokenizer.encode(l)])\n",
        "\n",
        "  # Creating chunks using the above defined function\n",
        "  encoded_train_lyrics = create_chunks(encoded_train_lyrics)\n",
        "  encoded_val_lyrics = create_chunks(encoded_val_lyrics)\n",
        "\n",
        "  # Restricting the training and validation set to 5000 and 500 respetively. (due to system and time constraints)\n",
        "  if len(encoded_train_lyrics) > 10000:\n",
        "    encoded_train_lyrics = encoded_train_lyrics[:10000]\n",
        "  if len(encoded_val_lyrics) > 500:\n",
        "    encoded_val_lyrics = encoded_val_lyrics[:500]\n",
        "\n",
        "  print (f'''\n",
        "  Size of Training and Validation set:\n",
        "  Training Size   : {len(encoded_train_lyrics)}\n",
        "  Validation Size : {len(encoded_val_lyrics)}\n",
        "  ''')\n",
        "\n",
        "  # Prepare the tensorflow datasets\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices(encoded_train_lyrics)\n",
        "  val_dataset = tf.data.Dataset.from_tensor_slices(encoded_val_lyrics)\n",
        "\n",
        "  train_dataset = train_dataset.map(create_data).shuffle(5000).batch(8)\n",
        "  val_dataset = val_dataset.map(create_data).batch(8)\n",
        "\n",
        "  return train_dataset, val_dataset\n",
        "\n",
        "##############################################################################################################################################################################\n",
        "\n",
        "## FUNCTION TO TRAIN THE MODEL:\n",
        "\n",
        "def training_model(train_data, validation_data,path,\n",
        "                   model = 'gpt2',\n",
        "                   learning_rate = 1e-7,\n",
        "                   n_epochs = 3):\n",
        "\n",
        "  # Load the pre-trained GPT-2 small model\n",
        "  model = TFGPT2LMHeadModel.from_pretrained(model)\n",
        "\n",
        "  # Loading Weights from drive:\n",
        "  model.load_weights(path)\n",
        "\n",
        "  ## Seting up the mmodel:\n",
        "\n",
        "  # Set up the optimizer and loss function\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate)\n",
        "  loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'], jit_compile = True)\n",
        "\n",
        "  # Training Model:\n",
        "\n",
        "  history  = model.fit(train_data, epochs = n_epochs, validation_data = validation_data)\n",
        "\n",
        "  return history, model"
      ],
      "metadata": {
        "id": "KsHrV9rIulBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TRAINING BEGINS HERE\n",
        "\n",
        "* We will fine tune all artist specific models for a particular Genre at once."
      ],
      "metadata": {
        "id": "jFUD8lem4EGV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxpklA9gmxBP"
      },
      "outputs": [],
      "source": [
        "# Based on the EDA, the top popular artists from each genre:\n",
        "genre_artist = {\n",
        "    'Country' : ['Luke_Combs', 'Johnny_Cash', 'John_Denver', 'Dolly_Parton', 'Morgan_Wallen'],\n",
        "    'RB'      : ['The_Weekend','Chris_Brown','Dua_Lipa','Ed_Sheeran','Justin_Bieber'],\n",
        "    'Rock'    : ['Queen', 'The_Beatles', 'Pink_Floyd', 'Maroon5', 'Cold_Play'],\n",
        "    'Misc'    : ['Scott_Cawthon','Emily_Dickinson', 'Robert_Burns'],\n",
        "    'Pop'     : ['Taylor_Swift',  'Ariana_Grande', 'Rihanna', 'Ed_Sheeran', 'Lana_Del_Rey'],\n",
        "    'Rap'     : ['Drake', 'Eminem', 'Kanye_West', 'Kendrick_Lamar', 'Nicki_Minaj']}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ARTISTS GENRE : COUNTRY"
      ],
      "metadata": {
        "id": "LEMAvMsK4I0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genre = 'Country'\n",
        "artists = genre_artist[genre]\n",
        "\n",
        "for artist in artists:\n",
        "  print (f'''\n",
        "  FINE-TUNING '{genre}' PRE_TRAINED MODEL FOR ARTIST '{artist}'\n",
        "  ''')\n",
        "\n",
        "  ## Getting the dataset:\n",
        "  try:\n",
        "    # Trying for pickle dataset\n",
        "    try:\n",
        "      with open(f'/content/drive/MyDrive/UNIV.AI/AI-3 Language Models/Project/Project Landing /Datasets/Artist_Dataset/{genre}/{artist}.pickle', 'rb') as f:\n",
        "        df = pickle.load(f)\n",
        "    # Trying for pandas dataset\n",
        "    except:\n",
        "        df = pd.read_csv(f'/content/drive/MyDrive/UNIV.AI/AI-3 Language Models/Project/Project Landing /Datasets/Artist_Dataset/{genre}/{artist}.csv')\n",
        "  except:\n",
        "    df = None\n",
        "    print (f'File not found for artist : {artist}')\n",
        "    break\n",
        "  ###############################################################################################################################################################\n",
        "\n",
        "  # Data Pre-Processing\n",
        "  songs  = pre_processing_lyrics(df)\n",
        "\n",
        "  # Preparing Tensorflow Dataset\n",
        "  train_data , val_data = prepare_dataset(songs)\n",
        "\n",
        "  # Training Model:\n",
        "  path = f'/content/drive/MyDrive/UNIV.AI/AI-3 Language Models/Project/Project Landing /Saved Models/Genre Models/{genre}_model_weights.h5'\n",
        "\n",
        "  _, model = training_model(train_data , val_data , path)\n",
        "\n",
        "  ################################################################################################################################################################\n",
        "\n",
        "  # saving model as .h5 file\n",
        "\n",
        "  model.save_weights(f'/content/drive/MyDrive/UNIV.AI/AI-3 Language Models/Project/Project Landing /Saved Models/Artist Models/{genre}_models/{artist}_weights.h5')\n",
        "\n",
        "  print (\"############################################################################################################################################################################################\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nsd9D1htwP-k",
        "outputId": "9f62a71a-766b-4945-fe94-2ea0729c488e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  FINE-TUNING 'Country' PRE_TRAINED MODEL FOR ARTIST 'Luke_Combs' \n",
            "  \n",
            "Number of Total Processed Lyrics : 67\n",
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 1155\n",
            "  Validation Size : 286\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "145/145 [==============================] - 151s 656ms/step - loss: 2.8232 - accuracy: 0.4604 - val_loss: 2.9418 - val_accuracy: 0.4524\n",
            "Epoch 2/3\n",
            "145/145 [==============================] - 40s 273ms/step - loss: 2.8153 - accuracy: 0.4616 - val_loss: 2.9395 - val_accuracy: 0.4530\n",
            "Epoch 3/3\n",
            "145/145 [==============================] - 44s 304ms/step - loss: 2.8080 - accuracy: 0.4619 - val_loss: 2.9375 - val_accuracy: 0.4534\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'Country' PRE_TRAINED MODEL FOR ARTIST 'Johnny_Cash' \n",
            "  \n",
            "Number of Total Processed Lyrics : 797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 5000\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 250s 309ms/step - loss: 3.0083 - accuracy: 0.4359 - val_loss: 2.5944 - val_accuracy: 0.4898\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 184s 294ms/step - loss: 2.9974 - accuracy: 0.4375 - val_loss: 2.5947 - val_accuracy: 0.4894\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 179s 286ms/step - loss: 2.9894 - accuracy: 0.4375 - val_loss: 2.5945 - val_accuracy: 0.4892\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'Country' PRE_TRAINED MODEL FOR ARTIST 'John_Denver' \n",
            "  \n",
            "Number of Total Processed Lyrics : 51\n",
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 666\n",
            "  Validation Size : 191\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "84/84 [==============================] - 130s 880ms/step - loss: 2.6868 - accuracy: 0.4869 - val_loss: 2.6498 - val_accuracy: 0.4942\n",
            "Epoch 2/3\n",
            "84/84 [==============================] - 23s 278ms/step - loss: 2.6841 - accuracy: 0.4856 - val_loss: 2.6475 - val_accuracy: 0.4941\n",
            "Epoch 3/3\n",
            "84/84 [==============================] - 25s 300ms/step - loss: 2.6797 - accuracy: 0.4875 - val_loss: 2.6454 - val_accuracy: 0.4945\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'Country' PRE_TRAINED MODEL FOR ARTIST 'Dolly_Parton' \n",
            "  \n",
            "Number of Total Processed Lyrics : 598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 5000\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 247s 309ms/step - loss: 2.4416 - accuracy: 0.5100 - val_loss: 2.5068 - val_accuracy: 0.4991\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 184s 295ms/step - loss: 2.4328 - accuracy: 0.5111 - val_loss: 2.5062 - val_accuracy: 0.4991\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 179s 286ms/step - loss: 2.4259 - accuracy: 0.5117 - val_loss: 2.5058 - val_accuracy: 0.4991\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'Country' PRE_TRAINED MODEL FOR ARTIST 'Morgan_Wallen' \n",
            "  \n",
            "Number of Total Processed Lyrics : 84\n",
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 1676\n",
            "  Validation Size : 290\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "210/210 [==============================] - 175s 557ms/step - loss: 2.8984 - accuracy: 0.4575 - val_loss: 2.7038 - val_accuracy: 0.4852\n",
            "Epoch 2/3\n",
            "210/210 [==============================] - 64s 306ms/step - loss: 2.8875 - accuracy: 0.4581 - val_loss: 2.6999 - val_accuracy: 0.4856\n",
            "Epoch 3/3\n",
            "210/210 [==============================] - 62s 296ms/step - loss: 2.8791 - accuracy: 0.4596 - val_loss: 2.6967 - val_accuracy: 0.4862\n",
            "############################################################################################################################################################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ARTISTS GENRE : RHYTHM & BLUES"
      ],
      "metadata": {
        "id": "kptJpR15Ju1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genre = 'RB'\n",
        "artists = genre_artist[genre]\n",
        "\n",
        "for artist in artists:\n",
        "  print (f'''\n",
        "  FINE-TUNING '{genre}' PRE_TRAINED MODEL FOR ARTIST '{artist}'\n",
        "  ''')\n",
        "\n",
        "  ## Getting the dataset:\n",
        "  try:\n",
        "    # Trying for pickle dataset\n",
        "    try:\n",
        "      with open(f'/content/drive/MyDrive/UNIV.AI/AI-3 Language Models/Project/Project Landing /Datasets/Artist_Dataset/{genre}/{artist}.pickle', 'rb') as f:\n",
        "        df = pickle.load(f)\n",
        "    # Trying for pandas dataset\n",
        "    except:\n",
        "        df = pd.read_csv(f'/content/drive/MyDrive/UNIV.AI/AI-3 Language Models/Project/Project Landing /Datasets/Artist_Dataset/{genre}/{artist}.csv')\n",
        "  except:\n",
        "    df = None\n",
        "    print (f'File not found for artist : {artist}')\n",
        "    break\n",
        "  ###############################################################################################################################################################\n",
        "\n",
        "  # Data Pre-Processing\n",
        "  songs  = pre_processing_lyrics(df)\n",
        "\n",
        "  # Preparing Tensorflow Dataset\n",
        "  train_data , val_data = prepare_dataset(songs)\n",
        "\n",
        "  # Training Model:\n",
        "  path = f'/content/drive/MyDrive/UNIV.AI/AI-3 Language Models/Project/Project Landing /Saved Models/Genre Models/{genre}_model_weights.h5'\n",
        "\n",
        "  _, model = training_model(train_data , val_data , path)\n",
        "\n",
        "  ################################################################################################################################################################\n",
        "\n",
        "  # saving model as .h5 file\n",
        "\n",
        "  model.save_weights(f'/content/drive/MyDrive/UNIV.AI/AI-3 Language Models/Project/Project Landing /Saved Models/Artist Models/{genre}_models/{artist}_weights.h5')\n",
        "\n",
        "  print (\"############################################################################################################################################################################################\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db9d0a7e-45c2-4a4c-aeec-552dfd238c35",
        "id": "0q7IP0z_Ju1q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  FINE-TUNING 'RB' PRE_TRAINED MODEL FOR ARTIST 'The_Weekend' \n",
            "  \n",
            "Number of Total Processed Lyrics : 192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 4435\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "555/555 [==============================] - 273s 361ms/step - loss: 2.4290 - accuracy: 0.5284 - val_loss: 2.3490 - val_accuracy: 0.5446\n",
            "Epoch 2/3\n",
            "555/555 [==============================] - 161s 290ms/step - loss: 2.4178 - accuracy: 0.5294 - val_loss: 2.3424 - val_accuracy: 0.5449\n",
            "Epoch 3/3\n",
            "555/555 [==============================] - 157s 283ms/step - loss: 2.4092 - accuracy: 0.5301 - val_loss: 2.3371 - val_accuracy: 0.5451\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'RB' PRE_TRAINED MODEL FOR ARTIST 'Chris_Brown' \n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Total Processed Lyrics : 544\n",
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 5000\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 254s 314ms/step - loss: 2.3368 - accuracy: 0.5099 - val_loss: 2.4654 - val_accuracy: 0.4875\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 184s 294ms/step - loss: 2.3250 - accuracy: 0.5107 - val_loss: 2.4619 - val_accuracy: 0.4886\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 185s 295ms/step - loss: 2.3170 - accuracy: 0.5113 - val_loss: 2.4597 - val_accuracy: 0.4892\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'RB' PRE_TRAINED MODEL FOR ARTIST 'Dua_Lipa' \n",
            "  \n",
            "Number of Total Processed Lyrics : 247\n",
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 3522\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "441/441 [==============================] - 236s 408ms/step - loss: 3.3982 - accuracy: 0.3906 - val_loss: 3.2202 - val_accuracy: 0.4361\n",
            "Epoch 2/3\n",
            "441/441 [==============================] - 134s 303ms/step - loss: 3.3293 - accuracy: 0.4029 - val_loss: 3.1638 - val_accuracy: 0.4455\n",
            "Epoch 3/3\n",
            "441/441 [==============================] - 132s 300ms/step - loss: 3.2843 - accuracy: 0.4088 - val_loss: 3.1211 - val_accuracy: 0.4507\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'RB' PRE_TRAINED MODEL FOR ARTIST 'Ed_Sheeran' \n",
            "  \n",
            "Number of Total Processed Lyrics : 296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1895 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 5000\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 242s 294ms/step - loss: 4.0866 - accuracy: 0.3038 - val_loss: 3.7701 - val_accuracy: 0.3027\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 173s 276ms/step - loss: 4.0100 - accuracy: 0.3163 - val_loss: 3.7030 - val_accuracy: 0.3097\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 179s 286ms/step - loss: 3.9668 - accuracy: 0.3212 - val_loss: 3.6591 - val_accuracy: 0.3139\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'RB' PRE_TRAINED MODEL FOR ARTIST 'Justin_Bieber' \n",
            "  \n",
            "Number of Total Processed Lyrics : 348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 5000\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 252s 310ms/step - loss: 3.5517 - accuracy: 0.3604 - val_loss: 3.2180 - val_accuracy: 0.4141\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 184s 294ms/step - loss: 3.4721 - accuracy: 0.3729 - val_loss: 3.1607 - val_accuracy: 0.4220\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 184s 294ms/step - loss: 3.4261 - accuracy: 0.3781 - val_loss: 3.1212 - val_accuracy: 0.4272\n",
            "############################################################################################################################################################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ARTISTS GENRE : ROCK"
      ],
      "metadata": {
        "id": "a2XnZk0QS7Ur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genre = 'Rock'\n",
        "artists = genre_artist[genre]\n",
        "\n",
        "for artist in artists:\n",
        "  print (f'''\n",
        "  FINE-TUNING '{genre}' PRE_TRAINED MODEL FOR ARTIST '{artist}'\n",
        "  ''')\n",
        "\n",
        "  ## Getting the dataset:\n",
        "  try:\n",
        "    # Trying for pickle dataset\n",
        "    try:\n",
        "      with open(f'/content/drive/MyDrive/UNIV.AI/AI-3 Language Models/Project/Project Landing /Datasets/Artist_Dataset/{genre}/{artist}.pickle', 'rb') as f:\n",
        "        df = pickle.load(f)\n",
        "    # Trying for pandas dataset\n",
        "    except:\n",
        "        df = pd.read_csv(f'/content/drive/MyDrive/UNIV.AI/AI-3 Language Models/Project/Project Landing /Datasets/Artist_Dataset/{genre}/{artist}.csv')\n",
        "  except:\n",
        "    df = None\n",
        "    print (f'File not found for artist : {artist}')\n",
        "    break\n",
        "  ###############################################################################################################################################################\n",
        "\n",
        "  # Data Pre-Processing\n",
        "  songs  = pre_processing_lyrics(df)\n",
        "\n",
        "  # Preparing Tensorflow Dataset\n",
        "  train_data , val_data = prepare_dataset(songs)\n",
        "\n",
        "  # Training Model:\n",
        "  path = f'/content/drive/MyDrive/UNIV.AI/AI-3 Language Models/Project/Project Landing /Saved Models/Genre Models/{genre}_model_weights.h5'\n",
        "\n",
        "  _, model = training_model(train_data , val_data , path)\n",
        "\n",
        "  ################################################################################################################################################################\n",
        "\n",
        "  # saving model as .h5 file\n",
        "\n",
        "  model.save_weights(f'/content/drive/MyDrive/UNIV.AI/AI-3 Language Models/Project/Project Landing /Saved Models/Artist Models/{genre}_models/{artist}_weights.h5')\n",
        "\n",
        "  print (\"############################################################################################################################################################################################\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd4ad9fa-925f-40a7-c462-0e0c93e2c2cb",
        "id": "u4fIDyxDS7U0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  FINE-TUNING 'Rock' PRE_TRAINED MODEL FOR ARTIST 'Queen' \n",
            "  \n",
            "Number of Total Processed Lyrics : 475\n",
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 5000\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 234s 277ms/step - loss: 2.5345 - accuracy: 0.5138 - val_loss: 2.3193 - val_accuracy: 0.5489\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 161s 257ms/step - loss: 2.5236 - accuracy: 0.5148 - val_loss: 2.3086 - val_accuracy: 0.5499\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 161s 258ms/step - loss: 2.5139 - accuracy: 0.5156 - val_loss: 2.2996 - val_accuracy: 0.5510\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'Rock' PRE_TRAINED MODEL FOR ARTIST 'The_Beatles' \n",
            "  \n",
            "Number of Total Processed Lyrics : 557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1778 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 5000\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 240s 282ms/step - loss: 2.3402 - accuracy: 0.5479 - val_loss: 2.3070 - val_accuracy: 0.5438\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 161s 257ms/step - loss: 2.3277 - accuracy: 0.5495 - val_loss: 2.3009 - val_accuracy: 0.5446\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 160s 256ms/step - loss: 2.3186 - accuracy: 0.5507 - val_loss: 2.2961 - val_accuracy: 0.5454\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'Rock' PRE_TRAINED MODEL FOR ARTIST 'Pink_Floyd' \n",
            "  \n",
            "Number of Total Processed Lyrics : 278\n",
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 2531\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "317/317 [==============================] - 203s 437ms/step - loss: 2.9347 - accuracy: 0.4604 - val_loss: 2.8373 - val_accuracy: 0.4675\n",
            "Epoch 2/3\n",
            "317/317 [==============================] - 82s 259ms/step - loss: 2.9232 - accuracy: 0.4617 - val_loss: 2.8286 - val_accuracy: 0.4689\n",
            "Epoch 3/3\n",
            "317/317 [==============================] - 85s 266ms/step - loss: 2.9173 - accuracy: 0.4621 - val_loss: 2.8208 - val_accuracy: 0.4699\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'Rock' PRE_TRAINED MODEL FOR ARTIST 'Maroon5' \n",
            "  \n",
            "Number of Total Processed Lyrics : 197\n",
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 3029\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "379/379 [==============================] - 219s 409ms/step - loss: 3.4969 - accuracy: 0.3611 - val_loss: 3.3603 - val_accuracy: 0.3835\n",
            "Epoch 2/3\n",
            "379/379 [==============================] - 98s 258ms/step - loss: 3.4179 - accuracy: 0.3759 - val_loss: 3.2999 - val_accuracy: 0.3932\n",
            "Epoch 3/3\n",
            "379/379 [==============================] - 99s 262ms/step - loss: 3.3690 - accuracy: 0.3829 - val_loss: 3.2585 - val_accuracy: 0.3999\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'Rock' PRE_TRAINED MODEL FOR ARTIST 'Cold_Play' \n",
            "  \n",
            "Number of Total Processed Lyrics : 223\n",
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 2719\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "340/340 [==============================] - 209s 421ms/step - loss: 2.4130 - accuracy: 0.5309 - val_loss: 2.2607 - val_accuracy: 0.5553\n",
            "Epoch 2/3\n",
            "340/340 [==============================] - 88s 260ms/step - loss: 2.4048 - accuracy: 0.5318 - val_loss: 2.2551 - val_accuracy: 0.5552\n",
            "Epoch 3/3\n",
            "340/340 [==============================] - 88s 258ms/step - loss: 2.3991 - accuracy: 0.5321 - val_loss: 2.2502 - val_accuracy: 0.5558\n",
            "############################################################################################################################################################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ARTISTS GENRE : POP"
      ],
      "metadata": {
        "id": "WfWf0DxmhgqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genre = 'Pop'\n",
        "artists = genre_artist[genre]\n",
        "\n",
        "for artist in artists:\n",
        "  print (f'''\n",
        "  FINE-TUNING '{genre}' PRE_TRAINED MODEL FOR ARTIST '{artist}'\n",
        "  ''')\n",
        "\n",
        "  ## Getting the dataset:\n",
        "  try:\n",
        "    # Trying for pickle dataset\n",
        "    try:\n",
        "      with open(f'/content/drive/MyDrive/UNIV.ai/Project Landing /Datasets/Artist_Dataset/{genre}/{artist}.pickle', 'rb') as f:\n",
        "        df = pickle.load(f)\n",
        "    # Trying for pandas dataset\n",
        "    except:\n",
        "        df = pd.read_csv(f'/content/drive/MyDrive/UNIV.ai/Project Landing /Datasets/Artist_Dataset/{genre}/{artist}.csv')\n",
        "  except:\n",
        "    df = None\n",
        "    print (f'File not found for artist : {artist}')\n",
        "    break\n",
        "  ###############################################################################################################################################################\n",
        "\n",
        "  # Data Pre-Processing\n",
        "  songs  = pre_processing_lyrics(df)\n",
        "\n",
        "  # Preparing Tensorflow Dataset\n",
        "  train_data , val_data = prepare_dataset(songs)\n",
        "\n",
        "  # Training Model:\n",
        "  path = f'/content/drive/MyDrive/UNIV.ai/Project Landing /Saved Models/Genre Models/{genre}_model_weights.h5'\n",
        "\n",
        "  _, model = training_model(train_data , val_data , path)\n",
        "\n",
        "  ################################################################################################################################################################\n",
        "\n",
        "  # saving model as .h5 file\n",
        "\n",
        "  model.save_weights(f'/content/drive/MyDrive/UNIV.ai/Project Landing /Saved Models/Artist Models/{genre}_models/{artist}_weights.h5')\n",
        "\n",
        "  print (\"############################################################################################################################################################################################\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a182ac3-446d-40e5-8859-8b06cfe957b4",
        "id": "mJsBLdPlhgqR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  FINE-TUNING 'Pop' PRE_TRAINED MODEL FOR ARTIST 'Taylor_Swift' \n",
            "  \n",
            "Number of Total Processed Lyrics : 479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2909 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 5000\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 230s 280ms/step - loss: 3.8649 - accuracy: 0.3152 - val_loss: 4.1921 - val_accuracy: 0.2750\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 161s 258ms/step - loss: 3.7697 - accuracy: 0.3319 - val_loss: 4.1252 - val_accuracy: 0.2863\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 164s 262ms/step - loss: 3.7183 - accuracy: 0.3389 - val_loss: 4.0852 - val_accuracy: 0.2915\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'Pop' PRE_TRAINED MODEL FOR ARTIST 'Ariana_Grande' \n",
            "  \n",
            "Number of Total Processed Lyrics : 252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1416 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 5000\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 234s 282ms/step - loss: 2.2546 - accuracy: 0.5396 - val_loss: 2.3560 - val_accuracy: 0.5422\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 160s 255ms/step - loss: 2.2419 - accuracy: 0.5412 - val_loss: 2.3503 - val_accuracy: 0.5429\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 164s 262ms/step - loss: 2.2340 - accuracy: 0.5421 - val_loss: 2.3457 - val_accuracy: 0.5438\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'Pop' PRE_TRAINED MODEL FOR ARTIST 'Rihanna' \n",
            "  \n",
            "Number of Total Processed Lyrics : 405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 5000\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 234s 282ms/step - loss: 3.5209 - accuracy: 0.3735 - val_loss: 2.8334 - val_accuracy: 0.4863\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 160s 255ms/step - loss: 3.4257 - accuracy: 0.3909 - val_loss: 2.7642 - val_accuracy: 0.5010\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 164s 263ms/step - loss: 3.3742 - accuracy: 0.3987 - val_loss: 2.7212 - val_accuracy: 0.5072\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'Pop' PRE_TRAINED MODEL FOR ARTIST 'Ed_Sheeran' \n",
            "  \n",
            "Number of Total Processed Lyrics : 281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 5000\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 235s 285ms/step - loss: 2.7193 - accuracy: 0.4864 - val_loss: 2.5592 - val_accuracy: 0.5010\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 165s 264ms/step - loss: 2.7051 - accuracy: 0.4879 - val_loss: 2.5578 - val_accuracy: 0.5016\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 165s 264ms/step - loss: 2.6941 - accuracy: 0.4893 - val_loss: 2.5566 - val_accuracy: 0.5025\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'Pop' PRE_TRAINED MODEL FOR ARTIST 'Lana_Del_Rey' \n",
            "  \n",
            "Number of Total Processed Lyrics : 436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 5000\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 243s 287ms/step - loss: 2.5003 - accuracy: 0.5132 - val_loss: 2.4905 - val_accuracy: 0.5360\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 166s 265ms/step - loss: 2.4892 - accuracy: 0.5145 - val_loss: 2.4824 - val_accuracy: 0.5371\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 165s 263ms/step - loss: 2.4797 - accuracy: 0.5150 - val_loss: 2.4756 - val_accuracy: 0.5379\n",
            "############################################################################################################################################################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ARTISTS GENRE : RAP"
      ],
      "metadata": {
        "id": "5QTUqd618WTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genre = 'Rap'\n",
        "artists = genre_artist[genre]\n",
        "\n",
        "for artist in artists:\n",
        "  print (f'''\n",
        "  FINE-TUNING '{genre}' PRE_TRAINED MODEL FOR ARTIST '{artist}'\n",
        "  ''')\n",
        "\n",
        "  ## Getting the dataset:\n",
        "  try:\n",
        "    # Trying for pickle dataset\n",
        "    try:\n",
        "      with open(f'/content/drive/MyDrive/UNIV.AI/Project AI 3 NLP/Project Landing /Datasets/Artist_Dataset/{genre}/{artist}.pickle', 'rb') as f:\n",
        "        df = pickle.load(f)\n",
        "    # Trying for pandas dataset\n",
        "    except:\n",
        "        df = pd.read_csv(f'/content/drive/MyDrive/UNIV.AI/Project AI 3 NLP/Project Landing /Datasets/Artist_Dataset/{genre}/{artist}.csv')\n",
        "  except:\n",
        "    df = None\n",
        "    print (f'File not found for artist : {artist}')\n",
        "    break\n",
        "  ###############################################################################################################################################################\n",
        "\n",
        "  # Data Pre-Processing\n",
        "  songs  = pre_processing_lyrics(df)\n",
        "\n",
        "  # Preparing Tensorflow Dataset\n",
        "  train_data , val_data = prepare_dataset(songs)\n",
        "\n",
        "  # Training Model:\n",
        "  path = f'/content/drive/MyDrive/UNIV.AI/Project AI 3 NLP/Project Landing /Saved Models/Genre Models/{genre}_model_weights.h5'\n",
        "\n",
        "  _, model = training_model(train_data , val_data , path)\n",
        "\n",
        "  ################################################################################################################################################################\n",
        "\n",
        "  # saving model as .h5 file\n",
        "\n",
        "  model.save_weights(f'/content/drive/MyDrive/UNIV.AI/Project AI 3 NLP/Project Landing /Saved Models/Artist Models/{genre}_models/{artist}_weights.h5')\n",
        "\n",
        "  print (\"############################################################################################################################################################################################\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d17c31-4814-4922-9e8f-f5d674f12639",
        "id": "rRhL_HEt8WTJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  FINE-TUNING 'Rap' PRE_TRAINED MODEL FOR ARTIST 'Drake' \n",
            "  \n",
            "Number of Total Processed Lyrics : 426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 10000\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1250/1250 [==============================] - 397s 267ms/step - loss: 2.9922 - accuracy: 0.4475 - val_loss: 3.1072 - val_accuracy: 0.4389\n",
            "Epoch 2/3\n",
            "1250/1250 [==============================] - 328s 262ms/step - loss: 2.9800 - accuracy: 0.4487 - val_loss: 3.1019 - val_accuracy: 0.4400\n",
            "Epoch 3/3\n",
            "1250/1250 [==============================] - 332s 266ms/step - loss: 2.9708 - accuracy: 0.4497 - val_loss: 3.0983 - val_accuracy: 0.4408\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'Rap' PRE_TRAINED MODEL FOR ARTIST 'Eminem' \n",
            "  \n",
            "Number of Total Processed Lyrics : 496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1487 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 10000\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1250/1250 [==============================] - 394s 271ms/step - loss: 2.9757 - accuracy: 0.4441 - val_loss: 3.1594 - val_accuracy: 0.4323\n",
            "Epoch 2/3\n",
            "1250/1250 [==============================] - 327s 262ms/step - loss: 2.9589 - accuracy: 0.4459 - val_loss: 3.1509 - val_accuracy: 0.4334\n",
            "Epoch 3/3\n",
            "1250/1250 [==============================] - 332s 266ms/step - loss: 2.9485 - accuracy: 0.4471 - val_loss: 3.1449 - val_accuracy: 0.4340\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'Rap' PRE_TRAINED MODEL FOR ARTIST 'Kanye_West' \n",
            "  \n",
            "Number of Total Processed Lyrics : 773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 10000\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1250/1250 [==============================] - 398s 276ms/step - loss: 2.9390 - accuracy: 0.4564 - val_loss: 2.8658 - val_accuracy: 0.4800\n",
            "Epoch 2/3\n",
            "1250/1250 [==============================] - 333s 266ms/step - loss: 2.9262 - accuracy: 0.4582 - val_loss: 2.8633 - val_accuracy: 0.4807\n",
            "Epoch 3/3\n",
            "1250/1250 [==============================] - 327s 261ms/step - loss: 2.9186 - accuracy: 0.4588 - val_loss: 2.8615 - val_accuracy: 0.4812\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'Rap' PRE_TRAINED MODEL FOR ARTIST 'Kendrick_Lamar' \n",
            "  \n",
            "Number of Total Processed Lyrics : 326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 10000\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1250/1250 [==============================] - 399s 276ms/step - loss: 3.2313 - accuracy: 0.4263 - val_loss: 3.2893 - val_accuracy: 0.4219\n",
            "Epoch 2/3\n",
            "1250/1250 [==============================] - 333s 267ms/step - loss: 3.2189 - accuracy: 0.4277 - val_loss: 3.2844 - val_accuracy: 0.4224\n",
            "Epoch 3/3\n",
            "1250/1250 [==============================] - 333s 267ms/step - loss: 3.2099 - accuracy: 0.4283 - val_loss: 3.2805 - val_accuracy: 0.4225\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'Rap' PRE_TRAINED MODEL FOR ARTIST 'Nicki_Minaj' \n",
            "  \n",
            "Number of Total Processed Lyrics : 323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 7054\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "882/882 [==============================] - 339s 321ms/step - loss: 4.3668 - accuracy: 0.2852 - val_loss: 4.2141 - val_accuracy: 0.2973\n",
            "Epoch 2/3\n",
            "882/882 [==============================] - 233s 264ms/step - loss: 4.2307 - accuracy: 0.3057 - val_loss: 4.1472 - val_accuracy: 0.3097\n",
            "Epoch 3/3\n",
            "882/882 [==============================] - 232s 263ms/step - loss: 4.1651 - accuracy: 0.3160 - val_loss: 4.1134 - val_accuracy: 0.3158\n",
            "############################################################################################################################################################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ARTISTS GENRE : MISCELLANEOUS"
      ],
      "metadata": {
        "id": "RmmAp1LGJjoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genre = 'Misc'\n",
        "artists = genre_artist[genre]\n",
        "\n",
        "for artist in artists:\n",
        "  print (f'''\n",
        "  FINE-TUNING '{genre}' PRE_TRAINED MODEL FOR ARTIST '{artist}'\n",
        "  ''')\n",
        "\n",
        "  ## Getting the dataset:\n",
        "  try:\n",
        "    # Trying for pickle dataset\n",
        "    try:\n",
        "      with open(f'/content/drive/MyDrive/UNIV.ai/Project Landing /Datasets/Artist_Dataset/{genre}/{artist}.pickle', 'rb') as f:\n",
        "        df = pickle.load(f)\n",
        "    # Trying for pandas dataset\n",
        "    except:\n",
        "        df = pd.read_csv(f'/content/drive/MyDrive/UNIV.ai/Project Landing /Datasets/Artist_Dataset/{genre}/{artist}.csv')\n",
        "  except:\n",
        "    df = None\n",
        "    print (f'File not found for artist : {artist}')\n",
        "    break\n",
        "  ###############################################################################################################################################################\n",
        "\n",
        "  # Data Pre-Processing\n",
        "  songs  = pre_processing_lyrics(df)\n",
        "\n",
        "  # Preparing Tensorflow Dataset\n",
        "  train_data , val_data = prepare_dataset(songs)\n",
        "\n",
        "  # Training Model:\n",
        "  path = f'/content/drive/MyDrive/UNIV.ai/Project Landing /Saved Models/Genre Models/{genre}_model_weights.h5'\n",
        "\n",
        "  _, model = training_model(train_data , val_data , path)\n",
        "\n",
        "  ################################################################################################################################################################\n",
        "\n",
        "  # saving model as .h5 file\n",
        "\n",
        "  model.save_weights(f'/content/drive/MyDrive/UNIV.ai/Project Landing /Saved Models/Artist Models/{genre}_models/{artist}_weights.h5')\n",
        "\n",
        "  print (\"############################################################################################################################################################################################\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a3cfb4f-5a25-4683-9ca0-b1e550c1d268",
        "id": "DZdD2Ps8Jjor"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1879 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  FINE-TUNING 'Misc' PRE_TRAINED MODEL FOR ARTIST 'Scott_Cawthon' \n",
            "  \n",
            "Number of Total Processed Lyrics : 87\n",
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 2012\n",
            "  Validation Size : 327\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "252/252 [==============================] - 173s 454ms/step - loss: 3.3668 - accuracy: 0.3814 - val_loss: 3.0136 - val_accuracy: 0.4106\n",
            "Epoch 2/3\n",
            "252/252 [==============================] - 69s 272ms/step - loss: 3.3383 - accuracy: 0.3844 - val_loss: 2.9989 - val_accuracy: 0.4128\n",
            "Epoch 3/3\n",
            "252/252 [==============================] - 68s 271ms/step - loss: 3.3167 - accuracy: 0.3873 - val_loss: 2.9879 - val_accuracy: 0.4135\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'Misc' PRE_TRAINED MODEL FOR ARTIST 'Emily_Dickinson' \n",
            "  \n",
            "Number of Total Processed Lyrics : 1167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 5000\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 235s 288ms/step - loss: 3.6446 - accuracy: 0.4212 - val_loss: 3.7121 - val_accuracy: 0.3076\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 173s 276ms/step - loss: 3.5988 - accuracy: 0.4282 - val_loss: 3.7239 - val_accuracy: 0.3029\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 168s 268ms/step - loss: 3.5718 - accuracy: 0.4301 - val_loss: 3.7354 - val_accuracy: 0.3003\n",
            "############################################################################################################################################################################################\n",
            "\n",
            "  FINE-TUNING 'Misc' PRE_TRAINED MODEL FOR ARTIST 'Robert_Burns' \n",
            "  \n",
            "Number of Total Processed Lyrics : 544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1310 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Size of Training and Validation set: \n",
            "  Training Size   : 5000\n",
            "  Validation Size : 500\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 238s 297ms/step - loss: 4.6275 - accuracy: 0.2618 - val_loss: 4.1463 - val_accuracy: 0.3186\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 172s 276ms/step - loss: 4.5956 - accuracy: 0.2643 - val_loss: 4.1282 - val_accuracy: 0.3206\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 172s 275ms/step - loss: 4.5710 - accuracy: 0.2665 - val_loss: 4.1148 - val_accuracy: 0.3223\n",
            "############################################################################################################################################################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H03fTQlvQ-LC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}